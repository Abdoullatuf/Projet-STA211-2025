{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "689d22e1",
   "metadata": {},
   "source": [
    "# Projet STA211 - Classification des publicités\n",
    "\n",
    "## Objectif\n",
    "Ce projet vise à développer un modèle de classification pour prédire si une image est une publicité ou non, en utilisant le dataset Internet Advertisements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ea1779",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, roc_auc_score\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.manifold import TSNE\n",
    "import prince\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "\n",
    "# Configuration des graphiques\n",
    "plt.style.use('seaborn-v0_8')  # Style moderne de seaborn\n",
    "sns.set_palette(\"husl\")  # Palette de couleurs harmonieuse\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4488eb",
   "metadata": {},
   "source": [
    "## 1. Chargement et exploration initiale des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab52bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement des données\n",
    "data = pd.read_csv('data_train.csv', sep='\\t')\n",
    "print(\"\\nDimensions du dataset:\", data.shape)\n",
    "print(\"\\nAperçu des premières lignes:\")\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d6ef23",
   "metadata": {},
   "source": [
    "## Analyse initiale des données\n",
    "\n",
    "- Le jeu de données contient 2459 observations et 4 variables\n",
    "- Les variables X1, X2, et X3 sont nos prédicteurs\n",
    "- La variable 'outcome' est notre cible, indiquant si l'image est une publicité ('ad.') ou non ('noad.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5aa8a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse des valeurs manquantes\n",
    "missing_values = data[['X1', 'X2', 'X3']].isnull().sum()\n",
    "print(\"\\nValeurs manquantes par variable:\")\n",
    "print(missing_values)\n",
    "\n",
    "# Distribution de la variable cible\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.countplot(x='outcome', data=data)\n",
    "plt.title('Distribution des classes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3216adb2",
   "metadata": {},
   "source": [
    "## Analyse des valeurs manquantes et distribution des classes\n",
    "\n",
    "### Valeurs manquantes :\n",
    "- X1 : 674 valeurs manquantes\n",
    "- X2 : 673 valeurs manquantes\n",
    "- X3 : 679 valeurs manquantes\n",
    "\n",
    "### Distribution des classes :\n",
    "- On observe un déséquilibre dans les classes\n",
    "- Les non-publicités sont plus nombreuses que les publicités (environ 80% vs 20%)\n",
    "- Cette distribution déséquilibrée devra être prise en compte dans notre modélisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8c4919",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse des variables continues\n",
    "plt.figure(figsize=(15, 5))\n",
    "for i, var in enumerate(['X1', 'X2', 'X3'], 1):\n",
    "    plt.subplot(1, 3, i)\n",
    "    sns.boxplot(x='outcome', y=var, data=data)\n",
    "    plt.title(f'Distribution de {var} par classe')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba78f6ab",
   "metadata": {},
   "source": [
    "## Analyse des distributions par variable\n",
    "\n",
    "### Observations clés :\n",
    "- **X1** : Montre une différence notable entre les classes, avec des valeurs généralement plus élevées pour les publicités\n",
    "- **X2** : Présente la plus grande séparation entre les classes, suggérant un bon pouvoir discriminant\n",
    "- **X3** : Montre également des différences entre les classes, mais avec plus de chevauchement\n",
    "\n",
    "### Implications pour la modélisation :\n",
    "- La variable X2 semble être le meilleur prédicteur individuel\n",
    "- La présence d'outliers suggère qu'une normalisation des données sera bénéfique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f69049a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Préparation des données pour l'AFM\n",
    "X = data[['X1', 'X2', 'X3']].copy()\n",
    "y = (data['outcome'] == 'ad.').astype(int)\n",
    "\n",
    "# Gestion des valeurs manquantes\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_imputed = pd.DataFrame(imputer.fit_transform(X), columns=X.columns)\n",
    "\n",
    "# Standardisation\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_imputed)\n",
    "\n",
    "# ACP\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# Visualisation des composantes principales\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(X_pca[:, 0], X_pca[:, 1], c=y, cmap='coolwarm', alpha=0.6)\n",
    "plt.title('Projection des données sur les deux premières composantes principales')\n",
    "plt.xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.1%})')\n",
    "plt.ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.1%})')\n",
    "plt.colorbar(label='Classe (0: non-ad, 1: ad)')\n",
    "plt.show()\n",
    "\n",
    "# Cercle des corrélations\n",
    "plt.figure(figsize=(10, 10))\n",
    "circle = plt.Circle((0, 0), 1, fill=False, color='gray', linestyle='--')\n",
    "plt.gca().add_artist(circle)\n",
    "\n",
    "for i, (comp1, comp2) in enumerate(zip(pca.components_[0], pca.components_[1])):\n",
    "    plt.arrow(0, 0, comp1, comp2, \n",
    "              head_width=0.05, head_length=0.1, \n",
    "              fc='red', ec='red', alpha=0.8)\n",
    "    label_pos = 1.1\n",
    "    plt.text(comp1 * label_pos, comp2 * label_pos, \n",
    "             f'X{i+1}', fontsize=12, ha='center', va='center')\n",
    "\n",
    "plt.xlim(-1.2, 1.2)\n",
    "plt.ylim(-1.2, 1.2)\n",
    "plt.axhline(y=0, color='gray', linestyle='--', alpha=0.3)\n",
    "plt.axvline(x=0, color='gray', linestyle='--', alpha=0.3)\n",
    "plt.grid(True, linestyle='--', alpha=0.3)\n",
    "plt.title('Cercle des corrélations')\n",
    "plt.xlabel('Première composante principale')\n",
    "plt.ylabel('Deuxième composante principale')\n",
    "plt.gca().set_aspect('equal', adjustable='box')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nPourcentage de variance expliquée par composante:\")\n",
    "for i, ratio in enumerate(pca.explained_variance_ratio_):\n",
    "    print(f\"PC{i+1}: {ratio:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b430da75",
   "metadata": {},
   "source": [
    "## Analyse en Composantes Principales (ACP)\n",
    "\n",
    "### Projection des données :\n",
    "- Les deux premières composantes principales expliquent environ 90% de la variance totale\n",
    "- PC1 explique environ 51.5% de la variance\n",
    "- PC2 explique environ 38.3% de la variance\n",
    "\n",
    "### Interprétation du cercle des corrélations :\n",
    "- **X1** : Fortement corrélé avec la première composante principale\n",
    "- **X2** : Corrélé positivement avec PC1 et PC2\n",
    "- **X3** : Corrélé négativement avec PC2\n",
    "\n",
    "### Implications :\n",
    "- Les variables sont bien représentées dans le plan principal\n",
    "- Il existe une structure claire dans les données\n",
    "- La séparation des classes est visible dans l'espace des composantes principales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d1b590",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Configuration et entraînement de la carte de Kohonen\n",
    "from minisom import MiniSom\n",
    "\n",
    "som = MiniSom(5, 10, X_scaled.shape[1], sigma=1.0, learning_rate=0.5)\n",
    "som.random_weights_init(X_scaled)\n",
    "som.train_random(X_scaled, 1000)\n",
    "\n",
    "# Visualisation de la carte\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.pcolor(som.distance_map().T, cmap='bone_r')\n",
    "plt.colorbar()\n",
    "\n",
    "# Ajout des points avec leurs classes\n",
    "y_array = np.array(y)\n",
    "for i, x in enumerate(X_scaled):\n",
    "    w = som.winner(x)\n",
    "    plt.plot(w[0]+.5, w[1]+.5, 'o', \n",
    "             markerfacecolor='None',\n",
    "             markeredgecolor='r' if y_array[i] == 1 else 'b', \n",
    "             markersize=10, \n",
    "             markeredgewidth=2)\n",
    "\n",
    "plt.title('Carte de Kohonen')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249eb084",
   "metadata": {},
   "source": [
    "## Analyse de la carte de Kohonen\n",
    "\n",
    "### Structure de la carte :\n",
    "- Les zones claires représentent des frontières entre les clusters\n",
    "- Les zones sombres représentent des groupes d'observations similaires\n",
    "\n",
    "### Distribution des classes :\n",
    "- Points rouges : publicités\n",
    "- Points bleus : non-publicités\n",
    "- On observe des regroupements naturels des classes\n",
    "\n",
    "### Implications pour la classification :\n",
    "- Les publicités tendent à se regrouper dans certaines régions spécifiques\n",
    "- Cette séparation spatiale suggère que les caractéristiques choisies sont pertinentes pour la classification\n",
    "- Certaines zones de chevauchement indiquent des cas potentiellement difficiles à classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b05dc1",
   "metadata": {},
   "source": [
    "## Conclusions générales\n",
    "\n",
    "1. **Qualité des données** :\n",
    "   - Présence de valeurs manquantes gérée par imputation\n",
    "   - Distribution déséquilibrée des classes à prendre en compte\n",
    "\n",
    "2. **Structure des données** :\n",
    "   - Forte structure révélée par l'ACP\n",
    "   - Variables bien corrélées avec les composantes principales\n",
    "   - Bonne séparation des classes visible dans les projections\n",
    "\n",
    "3. **Recommandations pour la modélisation** :\n",
    "   - Utiliser des techniques de gestion du déséquilibre des classes\n",
    "   - Exploiter les composantes principales comme features\n",
    "   - Considérer des modèles non-linéaires vu la structure complexe des données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ab42a1",
   "metadata": {},
   "source": [
    "## 6. Évolution des performances des modèles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffeb35bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour évaluer un modèle\n",
    "def evaluate_model(model, X, y, name):\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    scores = cross_val_score(model, X, y, cv=cv, scoring='f1')\n",
    "    return {\n",
    "        'name': name,\n",
    "        'mean_f1': scores.mean(),\n",
    "        'std_f1': scores.std()\n",
    "    }\n",
    "\n",
    "# Création des ensembles de caractéristiques\n",
    "X_original = X_scaled\n",
    "X_pca_features = np.column_stack((X_scaled, X_pca))\n",
    "X_enhanced = np.column_stack((X_scaled, X_pca, \n",
    "                             X_scaled[:, 1] * X_scaled[:, 2],  # Interaction X2*X3\n",
    "                             X_scaled[:, 1] ** 2,  # X2²\n",
    "                             X_scaled[:, 2] ** 2))  # X3²\n",
    "\n",
    "# Évaluation des différents modèles\n",
    "results = []\n",
    "\n",
    "# 1. Random Forest sur les données originales\n",
    "rf_original = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "results.append(evaluate_model(rf_original, X_original, y, 'RF Original'))\n",
    "\n",
    "# 2. Random Forest avec features PCA\n",
    "rf_pca = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "results.append(evaluate_model(rf_pca, X_pca_features, y, 'RF + PCA'))\n",
    "\n",
    "# 3. Random Forest avec features améliorées\n",
    "rf_enhanced = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "results.append(evaluate_model(rf_enhanced, X_enhanced, y, 'RF + Features Améliorées'))\n",
    "\n",
    "# 4. Stacking Classifier\n",
    "stacking_clf = StackingClassifier(\n",
    "    estimators=[\n",
    "        ('rf', RandomForestClassifier(n_estimators=100, random_state=42)),\n",
    "        ('gb', GradientBoostingClassifier(n_estimators=100, random_state=42))\n",
    "    ],\n",
    "    final_estimator=LogisticRegression(),\n",
    "    cv=5\n",
    ")\n",
    "results.append(evaluate_model(stacking_clf, X_enhanced, y, 'Stacking Classifier'))\n",
    "\n",
    "# Visualisation des résultats\n",
    "results_df = pd.DataFrame(results)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(results_df['name'], results_df['mean_f1'], yerr=results_df['std_f1'], capsize=5)\n",
    "plt.title('Évolution du score F1 selon les différentes approches')\n",
    "plt.ylabel('Score F1')\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylim(0, 1)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Affichage des résultats\n",
    "print(\"\\nRésultats détaillés:\")\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3737ffb8",
   "metadata": {},
   "source": [
    "## 7. Optimisation des hyperparamètres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b94ac9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Paramètres à optimiser\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Recherche des meilleurs paramètres\n",
    "grid_search = GridSearchCV(\n",
    "    RandomForestClassifier(random_state=42),\n",
    "    param_grid,\n",
    "    cv=5,\n",
    "    scoring='f1',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_enhanced, y)\n",
    "\n",
    "print(\"Meilleurs paramètres:\")\n",
    "print(grid_search.best_params_)\n",
    "print(\"\\nMeilleur score F1:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839e4788",
   "metadata": {},
   "source": [
    "## 8. Prédictions finales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ced630",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Chargement des données de test\n",
    "data_test = pd.read_csv('data_test.csv', sep='\\t')\n",
    "X_test = data_test[['X1', 'X2', 'X3']]\n",
    "\n",
    "# Préparation des données de test\n",
    "X_test_imputed = pd.DataFrame(imputer.transform(X_test), columns=X_test.columns)\n",
    "X_test_scaled = scaler.transform(X_test_imputed)\n",
    "X_test_pca = pca.transform(X_test_scaled)\n",
    "\n",
    "# Création des features améliorées pour le test\n",
    "X_test_enhanced = np.column_stack((X_test_scaled, X_test_pca, \n",
    "                                  X_test_scaled[:, 1] * X_test_scaled[:, 2],\n",
    "                                  X_test_scaled[:, 1] ** 2,\n",
    "                                  X_test_scaled[:, 2] ** 2))\n",
    "\n",
    "# Prédictions avec le meilleur modèle\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test_enhanced)\n",
    "y_pred_r = ['ad.' if pred == 1 else 'noad.' for pred in y_pred]\n",
    "\n",
    "# Sauvegarde des prédictions\n",
    "predictions_df = pd.DataFrame(y_pred_r, columns=['prediction'])\n",
    "predictions_df.to_csv('soumission_final_format_R.csv', index=False, header=False)\n",
    "\n",
    "# Statistiques des prédictions\n",
    "print(f\"Nombre total de prédictions: {len(y_pred_r)}\")\n",
    "print(f\"Nombre de publicités prédites: {sum(1 for x in y_pred_r if x == 'ad.')}\")\n",
    "print(f\"Proportion de publicités prédites: {sum(1 for x in y_pred_r if x == 'ad.')/len(y_pred_r):.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a71d4f9",
   "metadata": {},
   "source": [
    "## 9. Vérification des prédictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da511ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_predictions(file_path, expected_n=820):\n",
    "    \"\"\"\n",
    "    Vérifie que le fichier de prédictions respecte les critères de la fonction read_pred.\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): Chemin vers le fichier de prédictions\n",
    "        expected_n (int): Nombre attendu de prédictions\n",
    "    \n",
    "    Returns:\n",
    "        bool: True si toutes les vérifications passent\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Lecture des prédictions\n",
    "        y_pred = pd.read_csv(file_path, header=None)[0].values\n",
    "        \n",
    "        # Vérification 1: Nombre de prédictions\n",
    "        if len(y_pred) != expected_n:\n",
    "            raise ValueError(f\"Le nombre de prédictions est incorrect: {len(y_pred)} au lieu de {expected_n}\")\n",
    "        \n",
    "        # Vérification 2: Valeurs manquantes\n",
    "        if pd.isna(y_pred).any():\n",
    "            raise ValueError(\"Le vecteur de prédiction contient des valeurs manquantes (NA)\")\n",
    "        \n",
    "        # Vérification 3: Valeurs autorisées\n",
    "        unique_values = np.unique(y_pred)\n",
    "        if not all(val in [\"ad.\", \"noad.\"] for val in unique_values):\n",
    "            raise ValueError(f\"Le nom des modalités prédites doit être ad. ou noad. au lieu de {unique_values}\")\n",
    "        \n",
    "        # Vérification 4: Distribution des prédictions\n",
    "        print(\"\\nDistribution des prédictions:\")\n",
    "        print(pd.Series(y_pred).value_counts())\n",
    "        \n",
    "        print(\"\\nToutes les vérifications ont été passées avec succès!\")\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors de la vérification: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "# Vérification du fichier de prédictions\n",
    "verify_predictions('soumission_final_format_R.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf84528e",
   "metadata": {},
   "source": [
    "## 10. Conclusion\n",
    "\n",
    "Notre analyse complète a permis d'obtenir de bons résultats en combinant plusieurs techniques :\n",
    "\n",
    "1. **Préparation des données** :\n",
    "   - Gestion des valeurs manquantes\n",
    "   - Standardisation des variables\n",
    "   - Création de nouvelles variables (ACP, interactions)\n",
    "\n",
    "2. **Analyse exploratoire** :\n",
    "   - Analyse factorielle multiple (AFM)\n",
    "   - Cartes de Kohonen\n",
    "   - Visualisation des corrélations\n",
    "\n",
    "3. **Modélisation** :\n",
    "   - Random Forest\n",
    "   - Stacking Classifier\n",
    "   - Optimisation des hyperparamètres\n",
    "\n",
    "4. **Résultats** :\n",
    "   - Score F1 amélioré\n",
    "   - Bon équilibre entre précision et rappel\n",
    "   - Distribution des prédictions cohérente\n",
    "   - Vérification des prédictions réussie\n",
    "\n",
    "Les prédictions ont été sauvegardées dans le fichier `soumission_final_format_R.csv` au format attendu par la fonction `read_pred` de R. "
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
